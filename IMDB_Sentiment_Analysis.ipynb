{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b4db1ea",
   "metadata": {},
   "source": [
    "# DOMAIN: Digital content and entertainment industry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7908c86e",
   "metadata": {},
   "source": [
    "# PROJECT OBJECTIVE: \n",
    "\n",
    "**Build a sequential NLP classifier which can use input text parameters to determine the customer sentiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1ad992f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f712a85",
   "metadata": {},
   "source": [
    "# Import and analyse the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ec94f823",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d7c31888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train data set is: (25000,) Shape of y_train data set is: (25000,)\n",
      "Shape of X_test data set is: (25000,) Shape of y_test data set is: (25000,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of X_train data set is:', X_train.shape, 'Shape of y_train data set is:', y_train.shape)\n",
    "print('Shape of X_test data set is:', X_test.shape, 'Shape of y_test data set is:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b56fefe",
   "metadata": {},
   "source": [
    "# Perform relevant sequence adding on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4b69518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = np.concatenate((X_train, X_test), axis=0)\n",
    "sentiment = np.concatenate((y_train, y_test), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c1fc1a",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7a828a",
   "metadata": {},
   "source": [
    "**Print shape of features and labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8fa5149c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of categories\n",
    "\n",
    "np.unique(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ee1e98c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of reviews: (50000,)\n",
      "Total number of sentiments: (50000,)\n"
     ]
    }
   ],
   "source": [
    "print('Total number of reviews:', review.shape)\n",
    "print('Total number of sentiments:', sentiment.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e5569e",
   "metadata": {},
   "source": [
    "**Print value of any one feature and it's label**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c8c1fd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 617, 11, 3875, 17, 2, 14, 966, 78, 20, 9, 38, 78, 15, 25, 413, 2, 5, 28, 8, 106, 12, 8, 4, 130, 43, 8, 67, 48, 12, 100, 79, 101, 433, 5, 12, 127, 4, 769, 9, 38, 727, 12, 186, 398, 34, 6, 312, 396, 2, 707, 4, 732, 26, 1235, 21, 2, 128, 74, 4, 2, 5, 4, 116, 9, 1639, 10, 10, 4, 2, 2, 186, 8, 28, 77, 2586, 39, 4, 4135, 2, 7, 2, 2, 50, 161, 306, 8, 30, 6, 686, 204, 326, 11, 4, 226, 20, 10, 10, 13, 258, 14, 20, 8, 30, 38, 78, 15, 13, 1498, 91, 7, 4, 96, 143, 10, 10, 9859, 9064, 144, 3261, 27, 419, 11, 902, 29, 540, 887, 4, 278]\n"
     ]
    }
   ],
   "source": [
    "#displaying the reviwe of 20th record \n",
    "\n",
    "print(review[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9b53d1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#displaying the sentiment of 20th record \n",
    "\n",
    "print(sentiment[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "11da0e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 13, 447, 14, 20, 12, 9, 1281, 8, 79, 6, 3132, 7, 1208, 2, 2571, 5, 14, 20, 9462, 4000, 139, 5, 1127, 5896, 5, 2, 122, 12, 13, 69, 57, 326, 474, 30, 38, 3889, 34, 12, 51, 35, 480, 168, 33, 89, 1536, 9518, 235, 12, 16, 1211, 8, 106, 179, 2035, 75, 32, 391, 4, 997, 5, 4, 7529, 150, 552, 7, 453, 21, 14, 9, 38, 38, 275, 51, 571, 54, 36, 216, 145, 5, 353, 8, 412, 6, 113, 36, 191, 12, 93, 72, 55, 1887, 7, 6, 1058, 604, 7, 349, 15, 26, 2, 187, 416, 11, 938, 24, 502, 8, 2198, 191, 1666, 191, 28, 119, 5625, 191, 855, 19, 1280, 926, 36, 235, 484, 972, 14, 9, 6, 666, 1521, 5, 31, 15, 218, 7470, 195, 1243, 2002, 1194, 263, 2169, 44, 2571, 9518, 75, 40, 98, 150, 21, 38, 51, 12, 152, 306, 8, 28, 93, 101, 1474, 8, 98, 45, 99, 522, 38, 12, 16, 6, 87, 22, 21, 13, 3785, 6, 176, 13, 28, 57, 85, 8044]\n"
     ]
    }
   ],
   "source": [
    "#displaying the reviwe of 1050th record which has a sentiment of 1\n",
    "\n",
    "print(review[1050])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1540fe3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#displaying the sentiment of 1050th record which has a sentiment of 1\n",
    "\n",
    "print(sentiment[1050])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e248e6b",
   "metadata": {},
   "source": [
    "# Decode the feature value to get original sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "84b9b4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_index = imdb.get_word_index()\n",
    "review_words = {value:key for key, value in review_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7f8dfb3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"$ shown in australia as $ this incredibly bad movie is so bad that you become $ and have to watch it to the end just to see if it could get any worse and it does the storyline is so predictable it seems written by a high school $ class the sets are pathetic but $ better than the $ and the acting is wooden br br the $ $ seems to have been stolen from the props $ of $ $ there didn't seem to be a single original idea in the whole movie br br i found this movie to be so bad that i laughed most of the way through br br malcolm mcdowell should hang his head in shame he obviously needed the money\""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([review_words.get(i - 3, \"$\") for i in review[20]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e43d2d",
   "metadata": {},
   "source": [
    "**Vectorizing the data**\n",
    "\n",
    "Review with less than 10000 will be filled 0 so that everything will be equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "113914aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizing(sequences, dimension = 10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8c0efe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = vectorizing(review)\n",
    "sentiment = np.array(sentiment).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec02eeef",
   "metadata": {},
   "source": [
    "**Train and Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "09b5ccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_test = review[:10000]\n",
    "sentiment_test = sentiment[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8c68a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_train = review[10000:]\n",
    "sentiment_train = sentiment[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6391db",
   "metadata": {},
   "source": [
    "**Model Building**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a616c584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5335b04",
   "metadata": {},
   "source": [
    "Model :- **Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3050b8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(solver='lbfgs', penalty='l2',max_iter=500,C=1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "868bc1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, max_iter=500, random_state=42)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.fit(review_train, sentiment_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "06c044b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_log_reg = log_reg.predict(review_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a0a943",
   "metadata": {},
   "source": [
    "Model :- **Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "31727c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB = MultinomialNB()\n",
    "NB.fit(review_train, sentiment_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "02fa0582",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_NB = NB.predict(review_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd899a37",
   "metadata": {},
   "source": [
    "Model :- **Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f4af9df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5, n_jobs=-1, oob_score=True, random_state=42)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1, max_depth=5, n_estimators=100, oob_score=True)\n",
    "rf.fit(review_train, sentiment_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2cd1bc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_rf = rf.predict(review_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a29d99",
   "metadata": {},
   "source": [
    "Model :- **Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "67ae618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "# Input - Layer\n",
    "model.add(layers.Dense(50, activation = \"relu\", input_shape=(10000, )))\n",
    "\n",
    "# Hidden - Layers\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(50, activation = \"relu\"))\n",
    "\n",
    "model.add(layers.Dropout(0.1, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(50, activation = \"relu\"))\n",
    "\n",
    "# Output- Layer\n",
    "model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "#Compile Model\n",
    "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f96d63d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.3955 - accuracy: 0.8271 - val_loss: 0.2615 - val_accuracy: 0.8957\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.2127 - accuracy: 0.9187 - val_loss: 0.2614 - val_accuracy: 0.8960\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.1530 - accuracy: 0.9433 - val_loss: 0.2901 - val_accuracy: 0.8919\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.1063 - accuracy: 0.9634 - val_loss: 0.3285 - val_accuracy: 0.8874\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.0705 - accuracy: 0.9769 - val_loss: 0.4192 - val_accuracy: 0.8832\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.0514 - accuracy: 0.9827 - val_loss: 0.4498 - val_accuracy: 0.8865\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.0386 - accuracy: 0.9866 - val_loss: 0.5408 - val_accuracy: 0.8821\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.0339 - accuracy: 0.9882 - val_loss: 0.5499 - val_accuracy: 0.8772\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.0277 - accuracy: 0.9903 - val_loss: 0.5811 - val_accuracy: 0.8798\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.0260 - accuracy: 0.9913 - val_loss: 0.5925 - val_accuracy: 0.8787\n"
     ]
    }
   ],
   "source": [
    "NN_Model = model.fit(review_train, sentiment_train, epochs= 10, batch_size = 500, validation_data = (review_test, sentiment_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6146d1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "dfb242ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for Logistic Regression -  0.8716\n",
      "Accuracy score for Naive Bayes -  0.8496\n",
      "Accuracy score for Random Forest -  0.8192\n",
      "Accuracy score for Neural Network -  0.8858500003814698\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score for Logistic Regression - ', accuracy_score(sentiment_test, predict_log_reg))\n",
    "print('Accuracy score for Naive Bayes - ', accuracy_score(sentiment_test, predict_NB))\n",
    "print('Accuracy score for Random Forest - ', accuracy_score(sentiment_test, predict_rf))\n",
    "print('Accuracy score for Neural Network - ', np.mean(NN_Model.history['val_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e24be8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Classification Report for Logistic Regression \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.87      0.87      0.87      4947\n",
      "    Negative       0.88      0.87      0.87      5053\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('          Classification Report for Logistic Regression \\n')\n",
    "print(classification_report(sentiment_test, predict_log_reg, target_names=['Positive','Negative']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "357e1048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Classification Report for Naive Bayes \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.84      0.86      0.85      4947\n",
      "    Negative       0.86      0.84      0.85      5053\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('          Classification Report for Naive Bayes \\n')\n",
    "print(classification_report(sentiment_test, predict_NB, target_names=['Positive','Negative']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4968e4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Classification Report for Random Forest \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.85      0.78      0.81      4947\n",
      "    Negative       0.80      0.86      0.83      5053\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.82      0.82      0.82     10000\n",
      "weighted avg       0.82      0.82      0.82     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('          Classification Report for Random Forest \\n')\n",
    "print(classification_report(sentiment_test, predict_rf, target_names=['Positive','Negative']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2b59d1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_model = model.predict_classes(review_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "be1f17b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_model = predict_model[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b84103d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Classification Report for Neural Network \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.87      0.88      0.88      4947\n",
      "    Negative       0.88      0.87      0.88      5053\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('          Classification Report for Neural Network \\n')\n",
    "print(classification_report(sentiment_test, predict_model, target_names=['Positive','Negative']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4575413e",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "\n",
    "- On the Accuracy perspective **Neural Network** have bee in the top with **88%** while **Random Forest** with least of **81%**\n",
    "- On the preceision and recall ** Logistic Regression** and **Neural Network** both are at higher side\n",
    "- On the F1-Score **Neural Network** tops the list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab47c5e5",
   "metadata": {},
   "source": [
    "**Validating the Prediction with actual value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "beecd086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(predict_model[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "73b2f65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_test[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "900805fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(predict_model[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "88fc27f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_test[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94b18e0",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "- IMDB data set was loaded with pre defined train and test data frame\n",
    "- Data Analysis was performed after combining the test and train data set\n",
    "- Orginal sentence was displayed \n",
    "- 4 different models **Logistic Regression**, **Naive Bayes**, **Random Forest** and **Neural Network** model were built\n",
    "- Accuracy and classification report were created to finalise the best model\n",
    "- **Neural Network** is the best model with highest accuracy in the test data\n",
    "- Finally validated the **predicted sentiment** with **actual sentiment**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
